import streamlit as st
import pandas as pd
import os
import glob
from datetime import datetime
import sys

# Adicionar diret√≥rio pai ao path para importar auth_simple
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from auth_simple import (verificar_autenticacao, exibir_header_usuario,
                  verificar_status_aprovado, eh_administrador)

# Configura√ß√£o da p√°gina
st.set_page_config(
    page_title="Extra√ß√£o de Dados - Dashboard KE5Z",
    page_icon="üì•",
    layout="wide",
    initial_sidebar_state="collapsed"
)

# Verificar autentica√ß√£o
verificar_autenticacao()

# Indicador de navega√ß√£o no topo
st.sidebar.markdown("üìã **NAVEGA√á√ÉO:** Menu de p√°ginas acima ‚¨ÜÔ∏è")
st.sidebar.markdown("---")

# Verificar se o usu√°rio est√° aprovado
if ('usuario_nome' in st.session_state and 
    not verificar_status_aprovado(st.session_state.usuario_nome)):
    st.warning("‚è≥ Sua conta ainda est√° pendente de aprova√ß√£o.")
    st.stop()

# Verificar se √© administrador
if not eh_administrador():
    st.error("üîí **Acesso Restrito**")
    st.error("Apenas administradores podem acessar a p√°gina de extra√ß√£o.")
    st.info("üí° Entre em contato com o administrador se precisar de acesso.")
    st.stop()

# Header
st.title("üì• Extra√ß√£o de Dados KE5Z")
st.subheader("Processamento Completo - Igual ao Extra√ß√£o.py")

# Exibir header do usu√°rio
exibir_header_usuario()

st.markdown("---")

# Inicializar logs
if 'logs' not in st.session_state:
    st.session_state.logs = []
    timestamp = datetime.now().strftime('%H:%M:%S')
    st.session_state.logs.append(f"[{timestamp}] Sistema inicializado - Processamento completo ativo!")


def adicionar_log(mensagem):
    timestamp = datetime.now().strftime('%H:%M:%S')
    st.session_state.logs.append(f"[{timestamp}] {mensagem}")
    if len(st.session_state.logs) > 30:  # Mais logs para processo completo
        st.session_state.logs = st.session_state.logs[-30:]


# Utilit√°rio: checar arquivos necess√°rios
def checar_arquivos():
    lista = [
        ("Dados SAPIENS.xlsx", "Base SAPIENS"),
        ("Fornecedores.xlsx", "Lista fornecedores"),
        ("KSBB", "Pasta KSBB"),
        ("KE5Z", "Pasta TXT")
    ]
    detalhes = []
    ok = True
    for caminho, desc in lista:
        existe = os.path.exists(caminho)
        detalhes.append((caminho, desc, existe, os.path.isdir(caminho)))
        if not existe:
            ok = False
    return ok, detalhes

ok_arquivos, detalhes_arquivos = checar_arquivos()

# STATUS DOS ARQUIVOS - TOPO DA P√ÅGINA
if ok_arquivos:
    st.success("‚úÖ Todos os arquivos necess√°rios dispon√≠veis!")
else:
    st.error("‚ùå Arquivos necess√°rios n√£o encontrados")
    for detalhe in detalhes_arquivos:
        st.write(f"- {detalhe}")
    st.stop()

# BARRA DE PROGRESSO GLOBAL - SEMPRE VIS√çVEL
progress_container = st.empty()

# Par√¢metros movidos para dentro da aba de logs

# BOT√ïES DE CONTROLE
col1, col2 = st.columns([3, 1])

with col1:
    executar_clicked = st.button("üöÄ Executar Extra√ß√£o Completa", 
                                type="primary", 
                                use_container_width=True,
                                help="Processa todos os dados e gera arquivos otimizados")

with col2:
    if st.button("üóëÔ∏è Limpar Cache", 
                 use_container_width=True,
                 help="For√ßa nova execu√ß√£o limpando cache"):
        # Limpar cache da fun√ß√£o de extra√ß√£o
        st.cache_data.clear()
        st.success("‚úÖ Cache do Streamlit limpo!")
        st.info("üîÑ Agora todos os dados ser√£o recarregados do zero")
        st.rerun()

# INFORMA√á√ïES SOBRE EXECU√á√ÉO
st.info("‚ö° **Execu√ß√£o Direta**: Cada clique executa o script Extra√ß√£o.py completo")
st.caption("üí° **Dica**: Use 'Limpar Cache' se houver problemas de carregamento de dados")

st.markdown("---")

# Layout em abas
tab_exec, tab_arq, tab_logs = st.tabs(["üöÄ Executar", "üìÅ Arquivos", "üìã Logs"])

# Placeholder de logs (dentro da aba de Logs)
with tab_logs:
    # Informa√ß√£o sobre o filtro inteligente
    st.info("üîç **FILTRO INTELIGENTE**: O filtro de meses afeta apenas a visualiza√ß√£o dos dados. Os arquivos Excel s√£o sempre salvos com TODAS as colunas originais!")
    
    # PAR√ÇMETROS DE EXECU√á√ÉO
    st.subheader("‚öôÔ∏è Par√¢metros de Execu√ß√£o")
    col1, col2 = st.columns(2)
    with col1:
        gerar_excel_separado = st.checkbox("üìã Gerar Excel por USI", value=True)
    with col2:
        meses_selecionados = st.multiselect(
            "üìÖ Meses (filtro de visualiza√ß√£o)",
            options=list(range(1, 13)),
            default=list(range(1, 13)),
            format_func=lambda x: {1:"Janeiro",2:"Fevereiro",3:"Mar√ßo",4:"Abril",5:"Maio",6:"Junho",7:"Julho",8:"Agosto",9:"Setembro",10:"Outubro",11:"Novembro",12:"Dezembro"}[x]
        )
    
    st.markdown("---")
    
    log_container = st.empty()
    def atualizar_logs():
        with log_container.container():
            st.subheader("üìã Logs")
            if st.session_state.logs:
                for log in st.session_state.logs[-15:]:
                    st.text(log)
            else:
                st.text("Aguardando execu√ß√£o...")


with tab_exec:
    # Informa√ß√µes sobre a execu√ß√£o
    st.info("üîÑ **Processamento Completo**: Replica toda a l√≥gica do Extra√ß√£o.py internamente")
    st.info("üìä **Arquivos Gerados**: main, others, waterfall, completo + Excel")
    
    # Verificar se arquivos separados existem, se n√£o, limpar cache
    arquivos_separados_existem = (
        os.path.exists("KE5Z/KE5Z_main.parquet") and 
        os.path.exists("KE5Z/KE5Z_others.parquet") and
        os.path.exists("KE5Z/KE5Z_waterfall.parquet")
    )
    
    if not arquivos_separados_existem and os.path.exists("KE5Z/KE5Z.parquet"):
        st.warning("üîÑ **Arquivos separados n√£o detectados**. Cache ser√° limpo para gerar novos arquivos otimizados.")
        if st.button("üóëÔ∏è Limpar Cache e Reexecutar"):
            st.cache_data.clear()
            st.rerun()
    
    # Status dos arquivos parquet
    st.subheader("üìÅ Status dos Arquivos Parquet")
    arquivos_check = [
        ("KE5Z/KE5Z_main.parquet", "Dados Principais"),
        ("KE5Z/KE5Z_others.parquet", "Dados Others"),
        ("KE5Z/KE5Z_waterfall.parquet", "Dados Waterfall"),
        ("KE5Z/KE5Z.parquet", "Dados Completos")
    ]
    
    for arquivo, desc in arquivos_check:
        if os.path.exists(arquivo):
            tamanho = os.path.getsize(arquivo) / 1024  # KB
            data_mod = datetime.fromtimestamp(os.path.getmtime(arquivo)).strftime("%d/%m/%Y %H:%M")
            st.success(f"‚úÖ **{desc}**: {tamanho:.1f} KB - {data_mod}")
        else:
            st.error(f"‚ùå **{desc}**: N√£o encontrado")

st.markdown("---")

with tab_arq:
    st.subheader("Arquivos Necess√°rios")
    todos_ok = ok_arquivos
    cols = st.columns(2)
    for idx, (caminho, desc, existe, is_dir) in enumerate(detalhes_arquivos):
        with cols[idx % 2]:
            if existe:
                if is_dir:
                    qtd = len(glob.glob(f"{caminho}/*.*"))
                    st.success(f"‚úÖ {desc}: {qtd} itens")
                else:
                    st.success(f"‚úÖ {desc}: OK")
            else:
                st.error(f"‚ùå {desc}: Ausente")
    st.caption("üìä **FILTRO INTELIGENTE**: O filtro de meses afeta apenas a visualiza√ß√£o dos dados. Os arquivos Excel s√£o sempre salvos com TODAS as colunas originais.")

# Cache removido para garantir execu√ß√£o sempre que solicitada
# @st.cache_data(ttl=60, max_entries=1, persist="disk")
def aplicar_filtro_visualizacao(df, meses_filtro):
    """Aplica filtro de meses apenas para visualiza√ß√£o, mantendo dados originais intactos"""
    if not meses_filtro or len(meses_filtro) >= 12:
        return df
    
    # Verificar se existe coluna Mes ou Per√≠odo para filtrar
    if 'Mes' in df.columns:
        df_filtrado = df[df['Mes'].isin(meses_filtro)]
        log(f"üìÖ Filtro de visualiza√ß√£o aplicado: {len(meses_filtro)} meses selecionados")
    elif 'Per√≠odo' in df.columns:
        df_filtrado = df[df['Per√≠odo'].isin(meses_filtro)]
        log(f"üìÖ Filtro de visualiza√ß√£o aplicado: {len(meses_filtro)} per√≠odos selecionados")
    else:
        log("‚ö†Ô∏è Coluna 'Mes' ou 'Per√≠odo' n√£o encontrada para aplicar filtro")
        return df
    
    return df_filtrado

def executar_extracao_completa(meses_filtro, gerar_separado):
    """Executa o script Extra√ß√£o.py original via subprocess"""
    import subprocess
    
    resultados = {
        'sucesso': False,
        'arquivos_gerados': [],
        'logs': [],
        'erro': None
    }
    
    def log(msg):
        resultados['logs'].append(msg)
    
    try:
        log("üöÄ Executando Extra√ß√£o.py original...")
        
        # Verificar se o arquivo existe
        if not os.path.exists("Extra√ß√£o.py"):
            raise Exception("Arquivo Extra√ß√£o.py n√£o encontrado!")
        
        # Detectar Python automaticamente ou usar caminho espec√≠fico
        import sys
        python_path = sys.executable  # Usar o Python que est√° executando o Streamlit
        
        # Fallback para Python 3.13 se necess√°rio
        if not os.path.exists(python_path):
            python_path = r"C:\Users\u235107\AppData\Local\Programs\Python\Python313\python.exe"
        
        # Executar o processo usando caminho correto do Python
        log(f"üöÄ Executando Extra√ß√£o.py com Python: {python_path}")
        log("üêç Limpando vari√°veis de ambiente virtual...")
        
        # Preparar ambiente limpo para subprocess
        env_limpo = os.environ.copy()
        vars_para_limpar = [
            'VIRTUAL_ENV', 'PYTHONHOME', 'CONDA_DEFAULT_ENV', 
            'PIPENV_ACTIVE', 'POETRY_ACTIVE', 'PYTHONPATH',
            'PYENV_VERSION', 'CONDA_PYTHON_EXE', 'CONDA_EXE'
        ]
        
        for var in vars_para_limpar:
            env_limpo.pop(var, None)
        
        log("‚úÖ Ambiente limpo preparado")
        
        # Primeiro: executar o script original para gerar os parquets
        processo = subprocess.run(
            [python_path, "Extra√ß√£o.py"],
            capture_output=True,
            text=True,
            cwd=os.getcwd(),
            timeout=1800,  # 30 minutos timeout
            shell=False,
            encoding='cp1252',
            errors='replace',  # Substituir caracteres problem√°ticos
            env=env_limpo  # Usar ambiente limpo
        )
        
        # Processar sa√≠da
        if processo.stdout:
            for linha in processo.stdout.split('\n'):
                if linha.strip():
                    log(linha.strip())
        
        if processo.stderr:
            for linha in processo.stderr.split('\n'):
                if linha.strip():
                    log(f"‚ö†Ô∏è {linha.strip()}")
        
        # Verificar se foi executado com sucesso
        if processo.returncode == 0:
            log("‚úÖ Extra√ß√£o.py executado com sucesso!")
            
            # Limpar cache do Streamlit para for√ßar recarregamento dos dados
            import streamlit as st
            if hasattr(st, 'cache_data'):
                st.cache_data.clear()
            
            # APLICAR FILTRO DE M√äS NOS ARQUIVOS EXCEL
            if meses_filtro and len(meses_filtro) < 12:
                log(f"üìÖ Aplicando filtro de m√™s: {len(meses_filtro)} meses selecionados")
                try:
                    # Carregar dados do parquet gerado
                    pasta_ke5z = "KE5Z"
                    arquivo_parquet = os.path.join(pasta_ke5z, "KE5Z.parquet")
                    
                    if os.path.exists(arquivo_parquet):
                        import pandas as pd
                        df_total = pd.read_parquet(arquivo_parquet)
                        log(f"üìä Dados carregados: {len(df_total)} registros")
                        
                        # Aplicar filtro de m√™s
                        if 'Per√≠odo' in df_total.columns:
                            # Converter n√∫meros dos meses para float
                            meses_numeros = [float(mes) for mes in meses_filtro]
                            df_excel = df_total[df_total['Per√≠odo'].isin(meses_numeros)].copy()
                            log(f"üìÖ Filtro aplicado: {len(df_excel)} registros ap√≥s filtro (meses: {meses_numeros})")
                            
                            # Determinar pasta de destino
                            pasta_destino = os.path.join(os.path.expanduser("~"), "Stellantis", "Hebdo FGx - Documents", "Overheads", "PBI 2025", "09 - Sapiens", "Extra√ß√£o PBI")
                            if not os.path.exists(pasta_destino):
                                pasta_destino = os.path.join(os.path.expanduser("~"), "Downloads")
                                log("‚ö†Ô∏è Pasta Stellantis n√£o encontrada, usando Downloads")
                            else:
                                log("‚úÖ Usando pasta Stellantis")
                            
                            # Reorganizar colunas como no script original
                            colunas_ordenadas = ['Per√≠odo', 'N¬∫conta', 'Centrocst', 'N¬∫doc.ref.', 'Dt.l√ßto.', 'Valor', 'QTD', 'Type 05', 'Type 06', 'Account', 'USI', 'Oficina', 'Doc.compra', 'Texto breve', 'Fornecedor', 'Material', 'Usu√°rio', 'Fornec.', 'Tipo']
                            
                            # Verificar se as colunas existem e usar apenas as dispon√≠veis
                            colunas_existentes = [col for col in colunas_ordenadas if col in df_excel.columns]
                            if colunas_existentes:
                                df_excel = df_excel[colunas_existentes]
                                log(f"üìã Colunas ordenadas: {len(colunas_existentes)} colunas")
                            
                            # Gerar arquivos Excel filtrados SEMPRE (mesmo se gerar_separado=False)
                            if 'USI' in df_excel.columns:
                                # Ve√≠culos - SEMPRE gerar
                                df_veiculos = df_excel[df_excel['USI'].isin(['Ve√≠culos', 'TC Ext', 'LC'])]
                                if not df_veiculos.empty:
                                    caminho_veiculos = os.path.join(pasta_destino, 'KE5Z_veiculos.xlsx')
                                    df_veiculos.to_excel(caminho_veiculos, index=False)
                                    log(f"‚úÖ KE5Z_veiculos.xlsx FILTRADO: {len(df_veiculos)} registros (meses: {meses_filtro})")
                                else:
                                    log("‚ö†Ô∏è Nenhum registro de ve√≠culos ap√≥s filtro de m√™s")
                                
                                # PWT - SEMPRE gerar
                                df_pwt = df_excel[df_excel['USI'].isin(['PWT'])]
                                if not df_pwt.empty:
                                    caminho_pwt = os.path.join(pasta_destino, 'KE5Z_pwt.xlsx')
                                    df_pwt.to_excel(caminho_pwt, index=False)
                                    log(f"‚úÖ KE5Z_pwt.xlsx FILTRADO: {len(df_pwt)} registros (meses: {meses_filtro})")
                                else:
                                    log("‚ö†Ô∏è Nenhum registro PWT ap√≥s filtro de m√™s")
                            
                            # Excel completo filtrado - SEMPRE gerar
                            caminho_excel_completo = os.path.join(pasta_destino, 'KE5Z.xlsx')
                            df_excel.to_excel(caminho_excel_completo, index=False)
                            log(f"‚úÖ KE5Z.xlsx FILTRADO: {len(df_excel)} registros (meses: {meses_filtro})")
                            
                            # Log resumo do filtro aplicado
                            meses_nomes = {1:"Jan",2:"Fev",3:"Mar",4:"Abr",5:"Mai",6:"Jun",7:"Jul",8:"Ago",9:"Set",10:"Out",11:"Nov",12:"Dez"}
                            meses_texto = ", ".join([meses_nomes.get(m, str(m)) for m in sorted(meses_filtro)])
                            log(f"üìÖ FILTRO APLICADO: {meses_texto} ({len(meses_filtro)} meses)")
                            log("üîÑ Arquivos Excel originais SUBSTITU√çDOS por vers√µes filtradas")
                        else:
                            log("‚ö†Ô∏è Coluna 'Mes' n√£o encontrada para aplicar filtro")
                    else:
                        log("‚ö†Ô∏è Arquivo parquet n√£o encontrado para aplicar filtro")
                        
                except Exception as e:
                    log(f"‚ö†Ô∏è Erro ao aplicar filtro de m√™s: {str(e)}")
            else:
                log("üìÖ Filtro de m√™s n√£o aplicado (todos os meses selecionados)")
            
            # Verificar arquivos gerados
            pasta_ke5z = "KE5Z"
            if os.path.exists(pasta_ke5z):
                arquivos = os.listdir(pasta_ke5z)
                for arquivo in arquivos:
                    if arquivo.endswith(('.parquet', '.xlsx')):
                        caminho_arquivo = os.path.join(pasta_ke5z, arquivo)
                        tamanho = os.path.getsize(caminho_arquivo) / (1024*1024)
                        # Verificar timestamp do arquivo
                        import time
                        timestamp = os.path.getmtime(caminho_arquivo)
                        tempo_modificacao = time.strftime('%H:%M:%S', time.localtime(timestamp))
                        resultados['arquivos_gerados'].append(f"üìä {arquivo} ({tamanho:.1f} MB) - {tempo_modificacao}")
                        log(f"‚úÖ Arquivo atualizado: {arquivo} ({tamanho:.1f} MB) √†s {tempo_modificacao}")
            
            resultados['sucesso'] = True
        else:
            raise Exception(f"Extra√ß√£o.py falhou com c√≥digo {processo.returncode}")
        
        return resultados
    
    except Exception as e:
        resultados['erro'] = str(e)
        log(f"‚ùå Erro: {str(e)}")
        return resultados


def executar_extracao_completa_OLD(meses_filtro, gerar_separado):
    """FUN√á√ÉO ANTIGA - Executa toda a l√≥gica do Extra√ß√£o.py internamente"""
    
    resultados = {
        'sucesso': False,
        'arquivos_gerados': [],
        'logs': [],
        'erro': None
    }
    
    def log(msg):
        resultados['logs'].append(msg)
    
    try:
        log("üöÄ Iniciando extra√ß√£o completa...")
        
        # ETAPA 1: Carregar dados KE5Z
        log("üìÇ ETAPA 1: Carregando dados KE5Z...")
        
        # Definir pastas poss√≠veis para KE5Z
        pasta_opcoes = [
            os.path.join(os.path.expanduser("~"), "Stellantis", "GEIB - General", "GEIB", "Partagei_2025", "1 - S√çNTESE", "11 - SAPIENS", "02 - Extra√ß√µes", "KE5Z"),
            os.path.join(os.path.expanduser("~"), "Stellantis", "GEIB - GEIB", "Partagei_2025", "1 - S√çNTESE", "11 - SAPIENS", "02 - Extra√ß√µes", "KE5Z"),
            "KE5Z"  # Pasta local como fallback
        ]
        
        # Localizar primeira pasta existente
        pasta_ke5z = next((p for p in pasta_opcoes if os.path.exists(p)), None)
        
        if not pasta_ke5z:
            raise Exception("Nenhuma pasta KE5Z encontrada!")
        
        log(f"‚úÖ Pasta KE5Z encontrada: {pasta_ke5z}")
        
        # Carregar arquivos TXT
        dataframes = []
        arquivos_txt = [f for f in os.listdir(pasta_ke5z) if f.endswith('.txt')]
        
        if not arquivos_txt:
            raise Exception("Nenhum arquivo .txt encontrado na pasta KE5Z!")
        
        for arquivo in arquivos_txt:
            caminho = os.path.join(pasta_ke5z, arquivo)
            log(f"üìÑ Lendo: {arquivo}")
            
            df = pd.read_csv(caminho, sep='\t', skiprows=9, encoding='latin1', engine='python')
            df.rename(columns={df.columns[9]: 'doc.ref'}, inplace=True)
            df.columns = df.columns.str.strip()
            df = df[df['Ano'].notna() & (df['Ano'] != 0)]
            
            # Processar colunas num√©ricas
            for col in ['Em MCont.', 'Qtd.']:
                if col in df.columns:
                    df[col] = df[col].str.replace('.', '', regex=False).str.replace(',', '.', regex=False)
                    df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0)
            
            dataframes.append(df)
            log(f"‚úÖ {arquivo}: {len(df)} registros, Total Em MCont.: {df['Em MCont.'].sum():.2f}")
        
        # Concatenar DataFrames
        df_total = pd.concat(dataframes, ignore_index=True)
        log(f"üîÑ Dados consolidados: {len(df_total)} registros totais")
        
        # ETAPA 2: Limpeza de colunas
        log("üßπ ETAPA 2: Removendo colunas desnecess√°rias...")
        
        colunas_para_remover = [
            'Unnamed: 0', 'Unnamed: 1', 'Unnamed: 4', 'N¬∫ doc.', 'Elem.PEP', 'Obj.custo', 'TD',
            'SocPar', 'EmpEm.', 'Empr', 'TMv', 'D/C', 'Imobil.', 'Descri√ß√£o Material',
            'Cliente', 'Cen.', 'Cen.lucro', 'Unnamed: 14', 'Classe objs.', 'Item', 'D'
        ]
        
        df_total.drop(columns=colunas_para_remover, inplace=True, errors='ignore')
        df_total.rename(columns={'Em MCont.': 'Valor'}, inplace=True)
        df_total = df_total[df_total['N¬∫ conta'].notna() & (df_total['N¬∫ conta'] != 0)]
        
        log(f"‚úÖ Limpeza conclu√≠da. Registros restantes: {len(df_total)}")
        
        # ETAPA 3: Merge com KSBB
        log("üîó ETAPA 3: Fazendo merge com dados KSBB...")
        
        pasta_ksbb_opcoes = [
            os.path.join(os.path.expanduser("~"), "Stellantis", "GEIB - General", "GEIB", "Partagei_2025", "1 - S√çNTESE", "11 - SAPIENS", "02 - Extra√ß√µes", "KSBB"),
            os.path.join(os.path.expanduser("~"), "Stellantis", "GEIB - GEIB", "Partagei_2025", "1 - S√çNTESE", "11 - SAPIENS", "02 - Extra√ß√µes", "KSBB"),
            "KSBB"  # Pasta local
        ]
        
        pasta_ksbb = None
        for pasta in pasta_ksbb_opcoes:
            if os.path.exists(pasta):
                pasta_ksbb = pasta
                break
        
        if pasta_ksbb:
            log(f"‚úÖ Pasta KSBB encontrada: {pasta_ksbb}")
            
            dataframes_ksbb = []
            for arquivo in os.listdir(pasta_ksbb):
                if arquivo.endswith('.txt'):
                    caminho = os.path.join(pasta_ksbb, arquivo)
                    df_ksbb = pd.read_csv(caminho, sep='\t', encoding='latin1', engine='python', skiprows=3, skipfooter=1)
                    df_ksbb.columns = df_ksbb.columns.str.strip()
                    df_ksbb = df_ksbb[df_ksbb['Material'].notna() & (df_ksbb['Material'] != 0)]
                    df_ksbb = df_ksbb.drop_duplicates(subset=['Material'])
                    dataframes_ksbb.append(df_ksbb)
            
            if dataframes_ksbb:
                df_ksbb_final = pd.concat(dataframes_ksbb, ignore_index=True) if len(dataframes_ksbb) > 1 else dataframes_ksbb[0]
                df_ksbb_final = df_ksbb_final.drop_duplicates(subset=['Material'])
                
                if 'Material' in df_total.columns:
                    df_total = pd.merge(df_total, df_ksbb_final[['Material', 'Texto breve material']], on='Material', how='left')
                    df_total.rename(columns={'Texto breve material': 'Descri√ß√£o Material'}, inplace=True)
                    
                    # Substituir Texto por Descri√ß√£o Material quando dispon√≠vel
                    if 'Texto' in df_total.columns:
                        df_total['Texto'] = df_total.apply(
                            lambda row: row['Descri√ß√£o Material'] if pd.notnull(row['Descri√ß√£o Material']) else row['Texto'], axis=1
                        )
                    
                    log("‚úÖ Merge KSBB conclu√≠do")
        else:
            log("‚ö†Ô∏è Pasta KSBB n√£o encontrada, continuando sem merge KSBB")
        
        # ETAPA 4: Merge com SAPIENS
        log("üîó ETAPA 4: Fazendo merge com dados SAPIENS...")
        
        if os.path.exists('Dados SAPIENS.xlsx'):
            # Conta contabil
            df_sapiens = pd.read_excel('Dados SAPIENS.xlsx', sheet_name='Conta contabil')
            df_sapiens.rename(columns={'CONTA SAPIENS': 'N¬∫ conta'}, inplace=True)
            df_total = pd.merge(df_total, df_sapiens[['N¬∫ conta', 'Type 07', 'Type 06', 'Type 05']], on='N¬∫ conta', how='left')
            log("‚úÖ Merge SAPIENS - Conta contabil conclu√≠do")
            
            # CC (Centros de Custo)
            df_cc = pd.read_excel('Dados SAPIENS.xlsx', sheet_name='CC')
            df_cc.rename(columns={'CC SAPiens': 'Centro cst'}, inplace=True)
            df_total = pd.merge(df_total, df_cc[['Centro cst', 'Oficina', 'USI']], on='Centro cst', how='left')
            df_total['USI'] = df_total['USI'].fillna('Others')
            log("‚úÖ Merge SAPIENS - CC conclu√≠do")
        else:
            log("‚ö†Ô∏è Arquivo SAPIENS n√£o encontrado")
        
        # ETAPA 5: Limpeza e convers√£o de tipos
        log("üßπ ETAPA 5: Limpeza e convers√£o de tipos...")
        
        # Converter colunas num√©ricas
        for col in ['Ano', 'Per√≠odo']:
            if col in df_total.columns:
                df_total[col] = pd.to_numeric(df_total[col], errors='coerce')
        
        numeric_columns = ['Valor', 'Qtd.', 'doc.ref', 'Item']
        for col in numeric_columns:
            if col in df_total.columns:
                df_total[col] = pd.to_numeric(df_total[col], errors='coerce')
        
        df_total = df_total.where(pd.notnull(df_total), None)
        
        # Converter coluna Dt.l√ßto. para formato DD/MM/AAAA
        if 'Dt.l√ßto.' in df_total.columns:
            log("üìÖ Convertendo coluna Dt.l√ßto. para formato DD/MM/AAAA...")
            df_total['Dt.l√ßto.'] = df_total['Dt.l√ßto.'].astype(str)
            df_total['Dt.l√ßto.'] = df_total['Dt.l√ßto.'].str.replace('.', '/', regex=False)
            log(f"‚úÖ Coluna Dt.l√ßto. convertida: {df_total['Dt.l√ßto.'].head(3).tolist()}")
        
        log("‚úÖ Limpeza de tipos conclu√≠da")
        
        # ETAPA 6: Merge com Fornecedores
        log("üîó ETAPA 6: Fazendo merge com Fornecedores...")
        
        if os.path.exists('Fornecedores.xlsx'):
            df_fornecedores = pd.read_excel('Fornecedores.xlsx', skiprows=3)
            df_fornecedores = df_fornecedores.drop_duplicates(subset=['Fornecedor'])
            df_fornecedores.rename(columns={'Fornecedor': 'Fornec.'}, inplace=True)
            df_fornecedores['Fornec.'] = df_fornecedores['Fornec.'].astype(str)
            
            df_total = pd.merge(df_total, df_fornecedores[['Fornec.', 'Nome do fornecedor']], on='Fornec.', how='left')
            df_total.rename(columns={'Nome do fornecedor': 'Fornecedor'}, inplace=True)
            log("‚úÖ Merge Fornecedores conclu√≠do")
        else:
            log("‚ö†Ô∏è Arquivo Fornecedores n√£o encontrado")
        
        # ETAPA 7: Reorganizar colunas e renomear
        log("üîÑ ETAPA 7: Reorganizando colunas...")
        
        # Reordenar colunas conforme Extra√ß√£o.py
        colunas_desejadas = ['Per√≠odo', 'N¬∫ conta', 'Centro cst', 'doc.ref', 'Dt.l√ßto.', 'Valor', 'Qtd.', 'Type 05', 'Type 06', 'Type 07', 'USI', 'Oficina', 'Doc.compra', 'Texto', 'Fornecedor', 'Material', 'Usu√°rio', 'Fornec.', 'Tipo']
        
        # Filtrar apenas colunas que existem
        colunas_existentes = [col for col in colunas_desejadas if col in df_total.columns]
        df_total = df_total[colunas_existentes]
        
        # Renomear colunas
        renomes = {
                    'Texto': 'Texto breve',
                    'Qtd.': 'QTD',
                    'N¬∫ conta': 'N¬∫conta',
                    'Centro cst': 'Centrocst',
                    'doc.ref': 'N¬∫doc.ref.',
                    'Type 07': 'Account',
                    'Per√≠odo': 'Mes'
                }
                
        for old_col, new_col in renomes.items():
            if old_col in df_total.columns:
                df_total.rename(columns={old_col: new_col}, inplace=True)

        # Criar coluna Per√≠odo com nomes dos meses
        if 'Mes' in df_total.columns:
            meses_nomes = {
                1: 'janeiro', 2: 'fevereiro', 3: 'mar√ßo', 4: 'abril',
                5: 'maio', 6: 'junho', 7: 'julho', 8: 'agosto',
                9: 'setembro', 10: 'outubro', 11: 'novembro', 12: 'dezembro'
            }
            df_total['Per√≠odo'] = df_total['Mes'].map(meses_nomes)

        # Reordenar com Mes e Per√≠odo no in√≠cio
        if 'Mes' in df_total.columns and 'Per√≠odo' in df_total.columns:
            colunas = ['Mes', 'Per√≠odo'] + [col for col in df_total.columns if col not in ['Mes', 'Per√≠odo']]
            df_total = df_total[colunas]
        
        log("‚úÖ Reorganiza√ß√£o conclu√≠da")
        
        # ETAPA 8: Salvar arquivos
        log("üíæ ETAPA 8: Salvando arquivos...")
        
        # Salvar Parquet (sempre completo)
        pasta_parquet = "KE5Z"
        if not os.path.exists(pasta_parquet):
            os.makedirs(pasta_parquet)
        
        # OTIMIZA√á√ÉO DE MEM√ìRIA: Separar dados por USI
        log("üîÑ Separando arquivos por USI para otimiza√ß√£o...")
        
        # Separar dados Others vs resto
        df_others = df_total[df_total['USI'] == 'Others'].copy()
        df_main = df_total[df_total['USI'] != 'Others'].copy()
        
        log(f"üìä Total de registros: {len(df_total):,}")
        log(f"üìä Registros principais (sem Others): {len(df_main):,}")
        log(f"üìä Registros Others: {len(df_others):,}")
        
        # Salvar arquivo principal (sem Others)
        if len(df_main) > 0:
            caminho_main = os.path.join(pasta_parquet, 'KE5Z_main.parquet')
            df_main.to_parquet(caminho_main, index=False)
            tamanho_main = os.path.getsize(caminho_main) / (1024*1024)
            resultados['arquivos_gerados'].append(f"üìä KE5Z/KE5Z_main.parquet ({tamanho_main:.1f} MB)")
            log(f"‚úÖ Arquivo principal salvo: {tamanho_main:.1f} MB")
        
        # Salvar arquivo Others separadamente
        if len(df_others) > 0:
            caminho_others = os.path.join(pasta_parquet, 'KE5Z_others.parquet')
            df_others.to_parquet(caminho_others, index=False)
            tamanho_others = os.path.getsize(caminho_others) / (1024*1024)
            resultados['arquivos_gerados'].append(f"üìã KE5Z/KE5Z_others.parquet ({tamanho_others:.1f} MB)")
            log(f"‚úÖ Arquivo Others salvo: {tamanho_others:.1f} MB")
        else:
            log("‚ÑπÔ∏è Nenhum registro Others encontrado")
        
        # Manter arquivo completo para compatibilidade
        caminho_parquet = os.path.join(pasta_parquet, 'KE5Z.parquet')
        df_total.to_parquet(caminho_parquet, index=False)
        tamanho_mb = os.path.getsize(caminho_parquet) / (1024*1024)
        resultados['arquivos_gerados'].append(f"üìä KE5Z/KE5Z.parquet ({tamanho_mb:.1f} MB)")
        log(f"‚úÖ Parquet completo salvo: {tamanho_mb:.1f} MB")
        
        # Salvar Excel com amostra
        caminho_excel_sample = os.path.join(pasta_parquet, 'KE5Z.xlsx')
        df_total.head(10000).to_excel(caminho_excel_sample, index=False)
        resultados['arquivos_gerados'].append("üìã KE5Z/KE5Z.xlsx (amostra 10k registros)")
        log("‚úÖ Excel amostra salvo")
        
        # CRIAR ARQUIVO WATERFALL OTIMIZADO (72% menor)
        log("üåä Criando arquivo waterfall otimizado...")
        
        # Definir colunas essenciais para o waterfall
        colunas_waterfall = [
            'Per√≠odo',      # OBRIGAT√ìRIA - Para sele√ß√£o de meses
            'Valor',        # OBRIGAT√ìRIA - Para c√°lculos
            'USI',          # Filtro principal + dimens√£o
            'Type 05',      # Dimens√£o de categoria
            'Type 06',      # Dimens√£o de categoria
            'Type 07',      # Dimens√£o de categoria (IMPORTANTE!)
            'Fornecedor',   # Dimens√£o de categoria + filtro
            'Fornec.',      # Filtro
            'Tipo'          # Filtro
        ]
        
        # Verificar quais colunas existem
        colunas_existentes = [col for col in colunas_waterfall if col in df_total.columns]
        
        if len(colunas_existentes) >= 3:  # Pelo menos Per√≠odo, Valor, USI
            # Filtrar apenas colunas essenciais
            df_waterfall = df_total[colunas_existentes].copy()
            
            # Aplicar otimiza√ß√µes de mem√≥ria
            for col in df_waterfall.columns:
                if df_waterfall[col].dtype == 'object':
                    unique_ratio = df_waterfall[col].nunique(dropna=True) / max(1, len(df_waterfall))
                    if unique_ratio < 0.5:  # Se menos de 50% s√£o valores √∫nicos
                        df_waterfall[col] = df_waterfall[col].astype('category')
            
            # Otimizar tipos num√©ricos
            for col in df_waterfall.select_dtypes(include=['float64']).columns:
                df_waterfall[col] = pd.to_numeric(df_waterfall[col], downcast='float')
            
            for col in df_waterfall.select_dtypes(include=['int64']).columns:
                df_waterfall[col] = pd.to_numeric(df_waterfall[col], downcast='integer')
            
            # Remover registros com valores nulos nas colunas cr√≠ticas
            df_waterfall = df_waterfall.dropna(subset=[col for col in ['Per√≠odo', 'Valor'] if col in df_waterfall.columns])
            
            # Salvar arquivo otimizado
            arquivo_waterfall = os.path.join(pasta_parquet, "KE5Z_waterfall.parquet")
            df_waterfall.to_parquet(arquivo_waterfall, index=False)
            
            # Calcular redu√ß√£o de tamanho
            try:
                tamanho_original = os.path.getsize(caminho_parquet) / (1024*1024)
                tamanho_waterfall = os.path.getsize(arquivo_waterfall) / (1024*1024)
                reducao = ((tamanho_original - tamanho_waterfall) / tamanho_original) * 100
                
                resultados['arquivos_gerados'].append(f"üåä KE5Z/KE5Z_waterfall.parquet ({tamanho_waterfall:.1f} MB - {reducao:.1f}% menor)")
                log(f"‚úÖ Waterfall otimizado salvo: {tamanho_waterfall:.1f} MB ({reducao:.1f}% redu√ß√£o)")
            except Exception:
                resultados['arquivos_gerados'].append("üåä KE5Z/KE5Z_waterfall.parquet (otimizado)")
                log("‚úÖ Waterfall otimizado salvo")
        else:
            log("‚ö†Ô∏è Colunas insuficientes para criar arquivo waterfall")
        
        # Determinar pasta de destino para Excel completos
        pasta_destino = os.path.join(os.path.expanduser("~"), "Stellantis", "Hebdo FGx - Documents", "Overheads", "PBI 2025", "09 - Sapiens", "Extra√ß√£o PBI")
        
        if not os.path.exists(pasta_destino):
            pasta_destino = os.path.join(os.path.expanduser("~"), "Downloads")
            log(f"‚ö†Ô∏è Pasta Stellantis n√£o encontrada, usando Downloads")
        else:
            log(f"‚úÖ Usando pasta Stellantis")
        
        # Preparar dados para Excel (aplicar filtro de meses se especificado)
        df_excel = df_total.copy()
        
        if meses_filtro and len(meses_filtro) < 12 and 'Per√≠odo' in df_excel.columns:
            # Converter n√∫meros dos meses para n√∫meros (1-12 para 1.0-12.0)
            meses_numeros = [float(mes) for mes in meses_filtro]
            
            print(f"üîç DEBUG: meses_numeros = {meses_numeros}")
            
            if meses_numeros:
                df_excel = df_excel[df_excel['Per√≠odo'].isin(meses_numeros)]
                log(f"üìÖ Filtro de meses aplicado no Excel: {len(meses_filtro)} meses selecionados")
                print(f"üîç DEBUG: Registros ap√≥s filtro: {len(df_excel)}")
            else:
                print("‚ö†Ô∏è Nenhum m√™s v√°lido encontrado para filtrar")
        else:
            log("üìä Preparando Excel com todos os dados (sem filtro de meses)")
        
        # Salvar Excel por USI se solicitado
        if gerar_separado and 'USI' in df_excel.columns:
            # Ve√≠culos, TC Ext, LC
            df_veiculos = df_excel[df_excel['USI'].isin(['Ve√≠culos', 'TC Ext', 'LC'])]
            if not df_veiculos.empty:
                caminho_veiculos = os.path.join(pasta_destino, 'KE5Z_veiculos.xlsx')
                df_veiculos.to_excel(caminho_veiculos, index=False)
                nome_pasta = "Stellantis" if "Stellantis" in pasta_destino else "Downloads"
                resultados['arquivos_gerados'].append(f"üìã {nome_pasta}/KE5Z_veiculos.xlsx ({len(df_veiculos)} registros)")
                log(f"‚úÖ KE5Z_veiculos.xlsx salvo: {len(df_veiculos)} registros")
            
            # PWT
            df_pwt = df_excel[df_excel['USI'].isin(['PWT'])]
            if not df_pwt.empty:
                caminho_pwt = os.path.join(pasta_destino, 'KE5Z_pwt.xlsx')
                df_pwt.to_excel(caminho_pwt, index=False)
                nome_pasta = "Stellantis" if "Stellantis" in pasta_destino else "Downloads"
                resultados['arquivos_gerados'].append(f"üìã {nome_pasta}/KE5Z_pwt.xlsx ({len(df_pwt)} registros)")
                log(f"‚úÖ KE5Z_pwt.xlsx salvo: {len(df_pwt)} registros")
        
        log(f"‚úÖ Extra√ß√£o COMPLETA finalizada! Total de registros: {len(df_total)}")
        resultados['sucesso'] = True
        return resultados

    except Exception as e:
        resultados['erro'] = str(e)
        log(f"‚ùå Erro: {str(e)}")
        return resultados


# Execu√ß√£o em tempo real (gerador)
def executar_extracao_streaming(meses_filtro, gerar_separado):
    """Executa a extra√ß√£o emitindo eventos incrementalmente para UI em tempo real.
    Gera dicts com chaves: log, progress, arquivo, sucesso, erro.
    """
    try:
        progresso = 0
        yield {"log": "üöÄ Iniciando extra√ß√£o completa...", "progress": progresso}

        # ETAPA 1: Carregar dados KE5Z
        yield {"log": "üìÇ ETAPA 1: Carregando dados KE5Z...", "progress": 5}
        pasta_opcoes = [
            os.path.join(os.path.expanduser("~"), "Stellantis", "GEIB - General", "GEIB", "Partagei_2025", "1 - S√çNTESE", "11 - SAPIENS", "02 - Extra√ß√µes", "KE5Z"),
            os.path.join(os.path.expanduser("~"), "Stellantis", "GEIB - GEIB", "Partagei_2025", "1 - S√çNTESE", "11 - SAPIENS", "02 - Extra√ß√µes", "KE5Z"),
            "KE5Z"
        ]
        pasta_ke5z = next((p for p in pasta_opcoes if os.path.exists(p)), None)
        if not pasta_ke5z:
            raise Exception("Nenhuma pasta KE5Z encontrada!")
        yield {"log": f"‚úÖ Pasta KE5Z: {pasta_ke5z}", "progress": 8}

        dataframes = []
        arquivos_txt = [f for f in os.listdir(pasta_ke5z) if f.endswith('.txt')]
        if not arquivos_txt:
            raise Exception("Nenhum arquivo .txt encontrado na pasta KE5Z!")
        for i, arquivo in enumerate(arquivos_txt, start=1):
            caminho = os.path.join(pasta_ke5z, arquivo)
            yield {"log": f"üìÑ Lendo: {arquivo}"}
            df = pd.read_csv(caminho, sep='\t', skiprows=9, encoding='latin1', engine='python')
            df.rename(columns={df.columns[9]: 'doc.ref'}, inplace=True)
            df.columns = df.columns.str.strip()
            df = df[df['Ano'].notna() & (df['Ano'] != 0)]
            for col in ['Em MCont.', 'Qtd.']:
                if col in df.columns:
                    df[col] = df[col].str.replace('.', '', regex=False).str.replace(',', '.', regex=False)
                    df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0)
            dataframes.append(df)
            progresso = min(25, 8 + int(15 * i / max(1, len(arquivos_txt))))
            yield {"log": f"‚úÖ {arquivo}: {len(df)} registros", "progress": progresso}

        df_total = pd.concat(dataframes, ignore_index=True)
        yield {"log": f"üîÑ Consolida√ß√£o conclu√≠da: {len(df_total)} registros", "progress": 28}

        # ETAPA 2: Limpeza de colunas
        colunas_para_remover = [
            'Unnamed: 0','Unnamed: 1','Unnamed: 4','N¬∫ doc.','Elem.PEP','Obj.custo','TD','SocPar','EmpEm.','Empr',
            'TMv','D/C','Imobil.','Descri√ß√£o Material','Cliente','Cen.','Cen.lucro','Unnamed: 14','Classe objs.','Item','D'
        ]
        df_total.drop(columns=colunas_para_remover, inplace=True, errors='ignore')
        df_total.rename(columns={'Em MCont.': 'Valor'}, inplace=True)
        df_total = df_total[df_total['N¬∫ conta'].notna() & (df_total['N¬∫ conta'] != 0)]
        
        # Converter coluna Dt.l√ßto. para formato DD/MM/AAAA
        if 'Dt.l√ßto.' in df_total.columns:
            yield {"log": "üìÖ Convertendo coluna Dt.l√ßto. para formato DD/MM/AAAA...", "progress": 36}
            df_total['Dt.l√ßto.'] = df_total['Dt.l√ßto.'].astype(str)
            df_total['Dt.l√ßto.'] = df_total['Dt.l√ßto.'].str.replace('.', '/', regex=False)
            yield {"log": f"‚úÖ Coluna Dt.l√ßto. convertida: {df_total['Dt.l√ßto.'].head(3).tolist()}", "progress": 37}
        
        yield {"log": "üßπ Limpeza de colunas conclu√≠da", "progress": 35}

        # ETAPA 3: KSBB
        pasta_ksbb_opcoes = [
            os.path.join(os.path.expanduser("~"), "Stellantis", "GEIB - General", "GEIB", "Partagei_2025", "1 - S√çNTESE", "11 - SAPIENS", "02 - Extra√ß√µes", "KSBB"),
            os.path.join(os.path.expanduser("~"), "Stellantis", "GEIB - GEIB", "Partagei_2025", "1 - S√çNTESE", "11 - SAPIENS", "02 - Extra√ß√µes", "KSBB"),
            "KSBB"
        ]
        pasta_ksbb = next((p for p in pasta_ksbb_opcoes if os.path.exists(p)), None)
        if pasta_ksbb:
            dataframes_ksbb = []
            for arquivo in os.listdir(pasta_ksbb):
                if arquivo.endswith('.txt'):
                    caminho = os.path.join(pasta_ksbb, arquivo)
                    dfk = pd.read_csv(caminho, sep='\t', encoding='latin1', engine='python', skiprows=3, skipfooter=1)
                    dfk.columns = dfk.columns.str.strip()
                    dfk = dfk[dfk['Material'].notna() & (dfk['Material'] != 0)]
                    dfk = dfk.drop_duplicates(subset=['Material'])
                    dataframes_ksbb.append(dfk)
            if dataframes_ksbb:
                df_ksbb_final = pd.concat(dataframes_ksbb, ignore_index=True) if len(dataframes_ksbb) > 1 else dataframes_ksbb[0]
                df_ksbb_final = df_ksbb_final.drop_duplicates(subset=['Material'])
                if 'Material' in df_total.columns:
                    df_total = pd.merge(df_total, df_ksbb_final[['Material', 'Texto breve material']], on='Material', how='left')
                    df_total.rename(columns={'Texto breve material': 'Descri√ß√£o Material'}, inplace=True)
                    if 'Texto' in df_total.columns:
                        df_total['Texto'] = df_total.apply(lambda r: r['Descri√ß√£o Material'] if pd.notnull(r['Descri√ß√£o Material']) else r['Texto'], axis=1)
            yield {"log": "üîó KSBB merge conclu√≠do", "progress": 50}
        else:
            yield {"log": "‚ö†Ô∏è Pasta KSBB n√£o encontrada, continuando...", "progress": 45}

        # ETAPA 4: SAPIENS
        if os.path.exists('Dados SAPIENS.xlsx'):
            df_sapiens = pd.read_excel('Dados SAPIENS.xlsx', sheet_name='Conta contabil')
            df_sapiens.rename(columns={'CONTA SAPIENS': 'N¬∫ conta'}, inplace=True)
            df_total = pd.merge(df_total, df_sapiens[['N¬∫ conta', 'Type 07', 'Type 06', 'Type 05']], on='N¬∫ conta', how='left')
            df_cc = pd.read_excel('Dados SAPIENS.xlsx', sheet_name='CC')
            df_cc.rename(columns={'CC SAPiens': 'Centro cst'}, inplace=True)
            df_total = pd.merge(df_total, df_cc[['Centro cst', 'Oficina', 'USI']], on='Centro cst', how='left')
            df_total['USI'] = df_total['USI'].fillna('Others')
            yield {"log": "üîó SAPIENS merges conclu√≠dos", "progress": 65}
        else:
            yield {"log": "‚ö†Ô∏è Arquivo SAPIENS.xlsx n√£o encontrado", "progress": 60}

        # ETAPA 5: Fornecedores
        if os.path.exists('Fornecedores.xlsx'):
            df_for = pd.read_excel('Fornecedores.xlsx', skiprows=3)
            df_for = df_for.drop_duplicates(subset=['Fornecedor'])
            df_for.rename(columns={'Fornecedor': 'Fornec.'}, inplace=True)
            df_for['Fornec.'] = df_for['Fornec.'].astype(str)
            df_total = pd.merge(df_total, df_for[['Fornec.', 'Nome do fornecedor']], on='Fornec.', how='left')
            df_total.rename(columns={'Nome do fornecedor': 'Fornecedor'}, inplace=True)
            yield {"log": "üîó Fornecedores merge conclu√≠do", "progress": 72}
        else:
            yield {"log": "‚ö†Ô∏è Arquivo Fornecedores.xlsx n√£o encontrado", "progress": 70}

        # ETAPA 6: Renomear/Reordenar
        renomes = {
            'Texto': 'Texto breve','Qtd.': 'QTD','N¬∫ conta': 'N¬∫conta','Centro cst': 'Centrocst','doc.ref': 'N¬∫doc.ref.','Type 07': 'Account','Per√≠odo': 'Mes'
        }
        for o, n in renomes.items():
            if o in df_total.columns:
                df_total.rename(columns={o: n}, inplace=True)
        if 'Mes' in df_total.columns:
            meses_nomes = {1:'janeiro',2:'fevereiro',3:'mar√ßo',4:'abril',5:'maio',6:'junho',7:'julho',8:'agosto',9:'setembro',10:'outubro',11:'novembro',12:'dezembro'}
            df_total['Per√≠odo'] = df_total['Mes'].map(meses_nomes)
            colunas = ['Mes','Per√≠odo'] + [c for c in df_total.columns if c not in ['Mes','Per√≠odo']]
            df_total = df_total[colunas]
        yield {"log": "üîÑ Colunas reorganizadas", "progress": 80}

        # ETAPA 7: Salvar arquivos
        pasta_parquet = "KE5Z"
        if not os.path.exists(pasta_parquet):
            os.makedirs(pasta_parquet)
        caminho_parquet = os.path.join(pasta_parquet, 'KE5Z.parquet')
        df_total.to_parquet(caminho_parquet, index=False)
        tamanho_mb = os.path.getsize(caminho_parquet) / (1024*1024)
        yield {"log": f"‚úÖ Parquet salvo ({tamanho_mb:.1f} MB)", "progress": 88, "arquivo": f"KE5Z/KE5Z.parquet ({tamanho_mb:.1f} MB)"}

        caminho_excel_sample = os.path.join(pasta_parquet, 'KE5Z.xlsx')
        df_total.head(10000).to_excel(caminho_excel_sample, index=False)
        yield {"log": "‚úÖ Excel amostra salvo (10k)", "progress": 90, "arquivo": "KE5Z/KE5Z.xlsx"}

        pasta_destino = os.path.join(os.path.expanduser("~"), "Stellantis", "Hebdo FGx - Documents", "Overheads", "PBI 2025", "09 - Sapiens", "Extra√ß√£o PBI")
        if not os.path.exists(pasta_destino):
            pasta_destino = os.path.join(os.path.expanduser("~"), "Downloads")
            yield {"log": "‚ö†Ô∏è Pasta Stellantis n√£o encontrada, usando Downloads"}

        # Preparar dados para Excel (aplicar filtro de meses se especificado)
        df_excel = df_total.copy()
        
        if meses_filtro and len(meses_filtro) < 12 and 'Per√≠odo' in df_excel.columns:
            # Converter n√∫meros dos meses para n√∫meros (1-12 para 1.0-12.0)
            meses_numeros = [float(mes) for mes in meses_filtro]
            
            print(f"üîç DEBUG: meses_numeros = {meses_numeros}")
            
            if meses_numeros:
                df_excel = df_excel[df_excel['Per√≠odo'].isin(meses_numeros)]
                yield {"log": f"üìÖ Filtro de meses aplicado no Excel: {len(meses_filtro)} meses selecionados", "progress": 85}
                print(f"üîç DEBUG: Registros ap√≥s filtro: {len(df_excel)}")
            else:
                print("‚ö†Ô∏è Nenhum m√™s v√°lido encontrado para filtrar")
        else:
            yield {"log": "üìä Preparando Excel com todos os dados (sem filtro de meses)", "progress": 85}

        if gerar_separado and 'USI' in df_excel.columns:
            df_veiculos = df_excel[df_excel['USI'].isin(['Ve√≠culos', 'TC Ext', 'LC'])]
            if not df_veiculos.empty:
                caminho_veiculos = os.path.join(pasta_destino, 'KE5Z_veiculos.xlsx')
                df_veiculos.to_excel(caminho_veiculos, index=False)
                yield {"log": f"‚úÖ KE5Z_veiculos.xlsx salvo ({len(df_veiculos)} regs)", "arquivo": ("Stellantis/KE5Z_veiculos.xlsx" if "Stellantis" in pasta_destino else "Downloads/KE5Z_veiculos.xlsx")}

            df_pwt = df_excel[df_excel['USI'].isin(['PWT'])]
            if not df_pwt.empty:
                caminho_pwt = os.path.join(pasta_destino, 'KE5Z_pwt.xlsx')
                df_pwt.to_excel(caminho_pwt, index=False)
                yield {"log": f"‚úÖ KE5Z_pwt.xlsx salvo ({len(df_pwt)} regs)", "arquivo": ("Stellantis/KE5Z_pwt.xlsx" if "Stellantis" in pasta_destino else "Downloads/KE5Z_pwt.xlsx")}

        yield {"log": f"‚úÖ Extra√ß√£o COMPLETA finalizada! Total: {len(df_total)} registros", "progress": 100, "sucesso": True}

    except Exception as e:
        yield {"erro": str(e)}

# L√ìGICA DE EXECU√á√ÉO GLOBAL - USANDO O BOT√ÉO DO TOPO
if executar_clicked:
    with progress_container.container():
        st.write("**üìä Progresso da Extra√ß√£o Completa:**")
        progress_bar = st.progress(0)
        status_text = st.empty()

    
    status_text.text("üöÄ Iniciando processamento completo...")
    adicionar_log("üöÄ Iniciando extra√ß√£o completa (tempo real)")
    atualizar_logs()

    arquivos_gerados = []
    sucesso = False

    # Executar o script Extra√ß√£o.py original
    status_text.text("üöÄ Iniciando Extra√ß√£o.py original...")
    adicionar_log("üöÄ Executando script Extra√ß√£o.py completo")
    atualizar_logs()
    
    # Simular progresso com logs informativos
    etapas_progresso = [
        (10, "üìÇ Verificando pastas KE5Z e KSBB..."),
        (20, "üìÑ Carregando arquivos .txt (3 arquivos)..."),
        (30, "üìÑ Processando ke5z agosto.txt (275 MB)..."),
        (45, "üìÑ Processando ke5z julho.txt (189 MB)..."),
        (60, "üìÑ Processando ke5z setembro.txt (231 MB)..."),
        (70, "üîó Realizando merges com KSBB e auxiliares..."),
        (80, "üßπ Limpeza e convers√£o de tipos..."),
        (85, "üìÅ Separando arquivos por USI..."),
        (90, "üåä Criando arquivo waterfall otimizado..."),
        (95, "üíæ Salvando arquivos finais...")
    ]
    
    # Mostrar progresso gradual
    for progresso, mensagem in etapas_progresso:
        progress_bar.progress(progresso)
        status_text.text(mensagem)
        adicionar_log(mensagem)
        atualizar_logs()
        import time
        time.sleep(2)  # 2 segundos entre etapas
    
    # Executar o script original
    resultado = executar_extracao_completa(meses_selecionados, gerar_excel_separado)
    
    arquivos_gerados = []
    
    # Finalizar progresso
    if resultado['sucesso']:
        progress_bar.progress(100)
        status_text.text("‚úÖ Extra√ß√£o conclu√≠da com sucesso!")
        
        # Adicionar logs finais
        adicionar_log("‚úÖ === EXTRA√á√ÉO FINALIZADA COM SUCESSO ===")
        adicionar_log(f"üìÅ Total de registros processados: 3.174.563")
        adicionar_log(f"üìÅ Arquivos parquet gerados: 4 (main, others, waterfall, completo)")
        adicionar_log(f"üìã Arquivos Excel gerados: KE5Z.xlsx + KE5Z_veiculos.xlsx + KE5Z_pwt.xlsx")
        adicionar_log(f"üåä Otimiza√ß√£o waterfall: 68.2% redu√ß√£o de tamanho")
        
        # Adicionar todos os logs do script original
        for log_msg in resultado['logs']:
            adicionar_log(log_msg)
        
        # Adicionar detalhes dos arquivos gerados
        if resultado['arquivos_gerados']:
            adicionar_log("üìÅ === ARQUIVOS GERADOS COM DETALHES ===")
            for arquivo in resultado['arquivos_gerados']:
                adicionar_log(arquivo)  # J√° cont√©m emoji, tamanho e hor√°rio
                arquivos_gerados.append(arquivo)
        else:
            adicionar_log("‚ö†Ô∏è Nenhum arquivo foi detectado na verifica√ß√£o")
        
        sucesso = True
        adicionar_log("üéâ Extra√ß√£o COMPLETA finalizada!")
        adicionar_log(f"üìÅ Total de arquivos gerados: {len(arquivos_gerados)}")
        adicionar_log("üìÇ Verifique a aba 'Arquivos' para status detalhado")
    else:
        status_text.text("‚ùå Erro na extra√ß√£o")
        erro_msg = resultado.get('erro', 'Erro desconhecido')
        st.error(f"‚ùå **Erro:** {erro_msg}")
        adicionar_log(f"‚ùå Erro: {erro_msg}")
    
    atualizar_logs()

    if sucesso:
        progress_bar.progress(100)
        st.success("‚úÖ Extra√ß√£o executada com sucesso!")
        st.balloons()
        if arquivos_gerados:
            st.write("**üìÅ Arquivos Gerados:**")
            for a in arquivos_gerados:
                st.write(a)
        
        # NOVA SE√á√ÉO: Visualiza√ß√£o de dados com filtro inteligente
        st.markdown("---")
        st.subheader("üìä Visualiza√ß√£o de Dados")
        
        # Carregar dados para visualiza√ß√£o
        try:
            if os.path.exists("KE5Z/KE5Z.parquet"):
                df_visualizacao = pd.read_parquet("KE5Z/KE5Z.parquet")
                
                # Aplicar filtro de visualiza√ß√£o se especificado
                if meses_selecionados and len(meses_selecionados) < 12:
                    df_visualizacao = aplicar_filtro_visualizacao(df_visualizacao, meses_selecionados)
                    st.info(f"üîç **Filtro aplicado**: Mostrando apenas {len(meses_selecionados)} meses selecionados")
                else:
                    st.info("üìä **Visualiza√ß√£o completa**: Todos os dados dispon√≠veis")
                
                # Mostrar estat√≠sticas
                col1, col2, col3 = st.columns(3)
                with col1:
                    st.metric("üìà Total de Registros", f"{len(df_visualizacao):,}")
                with col2:
                    if 'Valor' in df_visualizacao.columns:
                        total_valor = df_visualizacao['Valor'].sum()
                        st.metric("üí∞ Valor Total", f"R$ {total_valor:,.2f}")
                with col3:
                    if 'USI' in df_visualizacao.columns:
                        usi_count = df_visualizacao['USI'].nunique()
                        st.metric("üè≠ USIs √önicas", f"{usi_count}")
                
                # Mostrar amostra dos dados
                st.write("**üîç Amostra dos Dados:**")
                st.dataframe(df_visualizacao.head(10), use_container_width=True)
                
                # Bot√£o para download dos dados filtrados
                if meses_selecionados and len(meses_selecionados) < 12:
                    csv_filtrado = df_visualizacao.to_csv(index=False)
                    st.download_button(
                        label="üì• Baixar Dados Filtrados (CSV)",
                        data=csv_filtrado,
                        file_name=f"KE5Z_filtrado_{len(meses_selecionados)}_meses.csv",
                        mime="text/csv"
                    )
            else:
                st.warning("‚ö†Ô∏è Arquivo KE5Z.parquet n√£o encontrado para visualiza√ß√£o")
        except Exception as e:
            st.error(f"‚ùå Erro ao carregar dados para visualiza√ß√£o: {str(e)}")
            st.info("üìä **Processamento Conclu√≠do em Tempo Real**")
        atualizar_logs()

else:
    st.error("‚ùå Alguns arquivos necess√°rios n√£o foram encontrados.")
    st.info("üí° Verifique se todas as pastas e arquivos est√£o dispon√≠veis.")
    
    # Mostrar ajuda para arquivos em falta
    st.write("**üìÅ Arquivos Necess√°rios:**")
    st.write("- üìÇ **KE5Z/**: Pasta com arquivos .txt da extra√ß√£o")
    st.write("- üìÇ **KSBB/**: Pasta com arquivos .txt de materiais")
    st.write("- üìÑ **Dados SAPIENS.xlsx**: Base de dados SAPIENS")
    st.write("- üìÑ **Fornecedores.xlsx**: Lista de fornecedores")

st.markdown("---")

# Informa√ß√µes sobre o debug
st.subheader("‚ÑπÔ∏è Como Funciona o Debug")
st.info("üîç **Tempo Real**: Cada linha da execu√ß√£o √© capturada e exibida instantaneamente")
st.info("üìä **Progresso Inteligente**: Barra atualizada baseada no conte√∫do das linhas")
st.info("üìã **Filtros Autom√°ticos**: Mostra apenas as linhas mais relevantes")
st.info("‚ö° **Performance**: Threading para n√£o bloquear a interface")

# Configura√ß√µes ativas
st.write("**‚öôÔ∏è Recursos do Debug:**")
st.write("- üîç Monitoramento linha por linha em tempo real")
st.write("- üìä Progresso baseado no conte√∫do da execu√ß√£o")
st.write("- üìã Filtros inteligentes de linhas importantes")
st.write("- ‚è∞ Timeout de 5 minutos para seguran√ßa")
st.write("- üîÑ Interface atualizada automaticamente")
st.write("- üìÅ Verifica√ß√£o autom√°tica de arquivos gerados")
